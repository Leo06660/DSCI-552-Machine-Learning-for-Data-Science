{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from math import log\n",
    "# import operator\n",
    "\n",
    "\n",
    "# \"\"\" 函式說明:計算給定資料集的經驗熵(夏農熵) Parameters:     dataSet - 資料集 Returns:     shannonEnt - 經驗熵(夏農熵) \"\"\"\n",
    "# def calcShannonEnt(dataSet):\n",
    "#     numEntires = len(dataSet)                       #返回資料集的行數\n",
    "#     labelCounts = {}                                #儲存每個標籤(Label)出現次數的字典\n",
    "#     for featVec in dataSet:                         #對每組特徵向量進行統計\n",
    "#         currentLabel = featVec[-1]                  #提取標籤(Label)資訊\n",
    "#         if currentLabel not in labelCounts.keys():  #如果標籤(Label)沒有放入統計次數的字典,新增進去\n",
    "#             labelCounts[currentLabel] = 0\n",
    "#         labelCounts[currentLabel] += 1              #Label計數\n",
    "#     shannonEnt = 0.0                                #經驗熵(夏農熵)\n",
    "#     for key in labelCounts:                         #計算夏農熵\n",
    "#         prob = float(labelCounts[key]) / numEntires #選擇該標籤(Label)的概率\n",
    "#         shannonEnt -= prob * log(prob, 2)           #利用公式計算\n",
    "#     return shannonEnt                               #返回經驗熵(夏農熵)\n",
    "\n",
    "# \"\"\" 函式說明:建立測試資料集 Parameters:     無 Returns:     dataSet - 資料集     labels - 特徵標籤 \"\"\"\n",
    "# def createDataSet():\n",
    "# #     dataSet = [[0, 0, 0, 0, 'no'],                      #資料集\n",
    "# #             [0, 0, 0, 1, 'no'],\n",
    "# #             [0, 1, 0, 1, 'yes'],\n",
    "# #             [0, 1, 1, 0, 'yes'],\n",
    "# #             [0, 0, 0, 0, 'no'],\n",
    "# #             [1, 0, 0, 0, 'no'],\n",
    "# #             [1, 0, 0, 1, 'no'],\n",
    "# #             [1, 1, 1, 1, 'yes'],\n",
    "# #             [1, 0, 1, 2, 'yes'],\n",
    "# #             [1, 0, 1, 2, 'yes'],\n",
    "# #             [2, 0, 1, 2, 'yes'],\n",
    "# #             [2, 0, 1, 1, 'yes'],\n",
    "# #             [2, 1, 0, 1, 'yes'],\n",
    "# #             [2, 1, 0, 2, 'yes'],\n",
    "# #             [2, 0, 0, 0, 'no']]\n",
    "# #     labels = ['年齡', '有工作', '有自己的房子', '信貸情況']        #特徵標籤\n",
    "#     dataSet =[[2, 2, 1, 4, 0, 0, 'No'],\n",
    "#              [2, 2, 1, 3, 1, 0, 'Yes'],\n",
    "#              [1, 1, 0, 3, 0, 1, 'Yes'],\n",
    "#              [1, 2, 0, 0, 0, 0, 'No'],\n",
    "#              [1, 2, 0, 0, 1, 1, 'Yes'],\n",
    "#              [1, 1, 0, 1, 0, 0, 'Yes'],\n",
    "#              [0, 1, 0, 1, 0, 0, 'No'],\n",
    "#              [1, 0, 1, 2, 0, 0, 'Yes'],\n",
    "#              [2, 2, 1, 3, 1, 1, 'Yes'],\n",
    "#              [0, 0, 0, 3, 0, 0, 'No'],\n",
    "#              [1, 0, 1, 4, 0, 1, 'No'],\n",
    "#              [0, 0, 0, 4, 1, 1, 'No'],\n",
    "#              [1, 2, 0, 2, 0, 1, 'Yes'],\n",
    "#              [2, 1, 1, 2, 1, 1, 'Yes'],\n",
    "#              [1, 1, 1, 1, 0, 1, 'Yes'],\n",
    "#              [2, 1, 0, 0, 0, 0, 'No'],\n",
    "#              [2, 0, 1, 3, 0, 1, 'Yes'],\n",
    "#              [0, 1, 0, 3, 0, 0, 'No'],\n",
    "#              [0, 2, 1, 2, 0, 0, 'No'],\n",
    "#              [1, 1, 0, 4, 0, 0, 'Yes'],\n",
    "#              [0, 1, 0, 3, 0, 0, 'Yes'],\n",
    "#              [0, 0, 1, 1, 1, 1, 'Yes']]\n",
    "\n",
    "#     labels = ['Occupied', 'Price', 'Music', 'Location', 'VIP', 'Favorite Beer']\n",
    "#     return dataSet, labels                          #返回資料集和分類屬性\n",
    "\n",
    "# \"\"\" 函式說明:按照給定特徵劃分資料集 Parameters:     dataSet - 待劃分的資料集     axis - 劃分資料集的特徵     value - 需要返回的特徵的值 Returns:     無 \"\"\"\n",
    "# def splitDataSet(dataSet, axis, value):     \n",
    "#     retDataSet = []                                     #建立返回的資料集列表\n",
    "#     for featVec in dataSet:                             #遍歷資料集\n",
    "#         if featVec[axis] == value:\n",
    "#             reducedFeatVec = featVec[:axis]             #去掉axis特徵\n",
    "#             reducedFeatVec.extend(featVec[axis+1:])     #將符合條件的新增到返回的資料集\n",
    "#             retDataSet.append(reducedFeatVec)\n",
    "#     return retDataSet                                   #返回劃分後的資料集\n",
    "\n",
    "# \"\"\" 函式說明:選擇最優特徵 Parameters:     dataSet - 資料集 Returns:     bestFeature - 資訊增益最大的(最優)特徵的索引值 \"\"\"\n",
    "# def chooseBestFeatureToSplit(dataSet):\n",
    "#     numFeatures = len(dataSet[0]) - 1                   #特徵數量\n",
    "#     baseEntropy = calcShannonEnt(dataSet)               #計算資料集的夏農熵\n",
    "#     bestInfoGain = 0.0                                  #資訊增益\n",
    "#     bestFeature = -1                                    #最優特徵的索引值\n",
    "#     for i in range(numFeatures):                        #遍歷所有特徵\n",
    "#         #獲取dataSet的第i個所有特徵\n",
    "#         featList = [example[i] for example in dataSet]\n",
    "#         uniqueVals = set(featList)                      #建立set集合{},元素不可重複\n",
    "#         newEntropy = 0.0                                #經驗條件熵\n",
    "#         for value in uniqueVals:                        #計算資訊增益\n",
    "#             subDataSet = splitDataSet(dataSet, i, value)        #subDataSet劃分後的子集\n",
    "#             prob = len(subDataSet) / float(len(dataSet))        #計運算元集的概率\n",
    "#             newEntropy += prob * calcShannonEnt(subDataSet)     #根據公式計算經驗條件熵\n",
    "#         infoGain = baseEntropy - newEntropy                     #資訊增益\n",
    "#         # print(\"第%d個特徵的增益為%.3f\" % (i, infoGain))           #列印每個特徵的資訊增益\n",
    "#         if (infoGain > bestInfoGain):                           #計算資訊增益\n",
    "#             bestInfoGain = infoGain                             #更新資訊增益，找到最大的資訊增益\n",
    "#             bestFeature = i                                     #記錄資訊增益最大的特徵的索引值\n",
    "#     return bestFeature                                          #返回資訊增益最大的特徵的索引值\n",
    "\n",
    "\n",
    "# \"\"\" 函式說明:統計classList中出現此處最多的元素(類標籤) Parameters:     classList - 類標籤列表 Returns:     sortedClassCount[0][0] - 出現此處最多的元素(類標籤) \"\"\"\n",
    "# def majorityCnt(classList):\n",
    "#     classCount = {}\n",
    "#     for vote in classList:  #統計classList中每個元素出現的次數\n",
    "#         if vote not in classCount.keys():classCount[vote] = 0   \n",
    "#         classCount[vote] += 1\n",
    "#     sortedClassCount = sorted(classCount.items(), key = operator.itemgetter(1), reverse = True)     #根據字典的值降序排序\n",
    "#     return sortedClassCount[0][0]   #返回classList中出現次數最多的元素\n",
    "\n",
    "# \"\"\" 函式說明:建立決策樹 Parameters:     dataSet - 訓練資料集     labels - 分類屬性標籤     featLabels - 儲存選擇的最優特徵標籤 Returns:     myTree - 決策樹 \"\"\"\n",
    "# def createTree(dataSet, labels, featLabels):\n",
    "#     classList = [example[-1] for example in dataSet]            #取分類標籤(是否放貸:yes or no)\n",
    "#     if classList.count(classList[0]) == len(classList):         #如果類別完全相同則停止繼續劃分\n",
    "#         return classList[0]\n",
    "#     if len(dataSet[0]) == 1:                                    #遍歷完所有特徵時返回出現次數最多的類標籤\n",
    "#         return majorityCnt(classList)\n",
    "#     bestFeat = chooseBestFeatureToSplit(dataSet)                #選擇最優特徵\n",
    "#     bestFeatLabel = labels[bestFeat]                            #最優特徵的標籤\n",
    "#     featLabels.append(bestFeatLabel)\n",
    "#     myTree = {bestFeatLabel:{}}                                 #根據最優特徵的標籤生成樹\n",
    "#     del(labels[bestFeat])                                       #刪除已經使用特徵標籤\n",
    "#     featValues = [example[bestFeat] for example in dataSet]     #得到訓練集中所有最優特徵的屬性值\n",
    "#     uniqueVals = set(featValues)                                #去掉重複的屬性值\n",
    "#     for value in uniqueVals:                                    #遍歷特徵，建立決策樹。                        \n",
    "#         myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), labels, featLabels)\n",
    "#     return myTree\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     dataSet, labels = createDataSet()\n",
    "#     featLabels = []\n",
    "#     myTree = createTree(dataSet, labels, featLabels)\n",
    "#     print(myTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "# \tdataSet = createDataSet()\n",
    "# \tlabels = ['outlook', 'tem', 'hum', 'windy']\n",
    "\t\n",
    "# \tlabelsForCreateTree = labels[:]\n",
    "# \tTree = createTree(dataSet, labelsForCreateTree )\n",
    "# \ttestvec = [1, 0, 1, 4]\n",
    "# \tprint (classify(Tree, labels, testvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_info_entropy(dataset):\n",
    "    n = len(dataset)\n",
    "    # 我们用Counter统计一下Y的数量\n",
    "#     print(type(dataset),'calculate_info_entropy')\n",
    "    labels = Counter(dataset[:, -1])\n",
    "    entropy = 0.0\n",
    "    # 套用信息熵公式\n",
    "    for k, v in labels.items():\n",
    "#         print('QQ')\n",
    "        prob = v / n\n",
    "        entropy -= prob * math.log(prob, 2)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, idx):\n",
    "   # idx是要拆分的特征下标\n",
    "    splitData = collections.defaultdict(list)\n",
    "    for data in dataset:\n",
    "       # 这里删除了idx这个特征的取值，因为用不到了\n",
    "        splitData[data[idx]].append(np.delete(data, idx))\n",
    "    return list(splitData.values()), list(splitData.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_feature_to_split(dataset):\n",
    "    n = len(dataset[0])-1\n",
    "    m = len(dataset)\n",
    "    # 切分之前的信息熵\n",
    "#     print(type(dataset),'choose_feature_to_split')\n",
    "    entropy = calculate_info_entropy(dataset)\n",
    "    bestGain = 0.0\n",
    "    feature = -1\n",
    "    for i in range(n):\n",
    "#         print('?')\n",
    "       # 根据特征i切分\n",
    "        split_data, _ = split_dataset(dataset, i)\n",
    "        new_entropy = 0.0\n",
    "        # 计算切分后的信息熵\n",
    "        for data in split_data:\n",
    "            prob = len(data) / m\n",
    "            new_entropy += prob * calculate_info_entropy(np.array(data))\n",
    "        # 获取信息增益\n",
    "        gain = entropy - new_entropy\n",
    "        if gain > bestGain:\n",
    "            bestGain = gain\n",
    "            feature = i\n",
    "#     print('@',feature)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decision_tree(dataset, feature_names):\n",
    "    dataset = np.array(dataset)\n",
    "    counter = Counter(dataset[:,-1])\n",
    "    # 如果数据集值剩下了一类，直接返回\n",
    "    if len(counter) == 1:\n",
    "        return dataset[0, -1]\n",
    "    \n",
    "    # 如果所有特征都已经切分完了，也直接返回\n",
    "    if len(dataset[0]) == 1:\n",
    "        return counter.most_common(1)[0][0]\n",
    "    \n",
    "    # 寻找最佳切分的特征\n",
    "#     print(type(dataset),'create_decision_tree')\n",
    "    fidx = choose_feature_to_split(dataset)\n",
    "    fname = feature_names[fidx]\n",
    "    \n",
    "#     print(fname)\n",
    "    node = {fname: {}}\n",
    "    feature_names.remove(fname)\n",
    "    \n",
    "    # 递归调用，对每一个切分出来的取值递归建树\n",
    "    split_data, vals = split_dataset(dataset, fidx)\n",
    "#     print('@@@',split_data,'   ###',vals)\n",
    "    for data, val in zip(split_data, vals):\n",
    "#         print('@@',data,'??',val)\n",
    "        node[fname][val] = create_decision_tree(data, feature_names[:])\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "d =[[2, 2, 1, 4, 0, 0, 'No'],\n",
    "         [2, 2, 1, 3, 1, 0, 'Yes'],\n",
    "         [1, 1, 0, 3, 0, 1, 'Yes'],\n",
    "         [1, 2, 0, 0, 0, 0, 'No'],\n",
    "         [1, 2, 0, 0, 1, 1, 'Yes'],\n",
    "         [1, 1, 0, 1, 0, 0, 'Yes'],\n",
    "         [0, 1, 0, 1, 0, 0, 'No'],\n",
    "         [1, 0, 1, 2, 0, 0, 'Yes'],\n",
    "         [2, 2, 1, 3, 1, 1, 'Yes'],\n",
    "         [0, 0, 0, 3, 0, 0, 'No'],\n",
    "         [1, 0, 1, 4, 0, 1, 'No'],\n",
    "         [0, 0, 0, 4, 1, 1, 'No'],\n",
    "         [1, 2, 0, 2, 0, 1, 'Yes'],\n",
    "         [2, 1, 1, 2, 1, 1, 'Yes'],\n",
    "         [1, 1, 1, 1, 0, 1, 'Yes'],\n",
    "         [2, 1, 0, 0, 0, 0, 'No'],\n",
    "         [2, 0, 1, 3, 0, 1, 'Yes'],\n",
    "         [0, 1, 0, 3, 0, 0, 'No'],\n",
    "         [0, 2, 1, 2, 0, 0, 'No'],\n",
    "         [1, 1, 0, 4, 0, 0, 'Yes'],\n",
    "         [0, 1, 0, 3, 0, 0, 'Yes'],\n",
    "         [0, 0, 1, 1, 1, 1, 'Yes']]\n",
    "# dataset=[['High', 'Expensive', 'Loud', 'Talpiot', 'No', 'No', 'No'],\n",
    "#  ['High', 'Expensive', 'Loud', 'City-Center', 'Yes', 'No', 'Yes'],\n",
    "#  ['Moderate', 'Normal', 'Quiet', 'City-Center', 'No', 'Yes', 'Yes'],\n",
    "#  ['Moderate', 'Expensive', 'Quiet', 'German-Colony', 'No', 'No', 'No'],\n",
    "#  ['Moderate', 'Expensive', 'Quiet', 'German-Colony', 'Yes', 'Yes', 'Yes'],\n",
    "#  ['Moderate', 'Normal', 'Quiet', 'Ein-Karem', 'No', 'No', 'Yes'],\n",
    "#  ['Low', 'Normal', 'Quiet', 'Ein-Karem', 'No', 'No', 'No'],\n",
    "#  ['Moderate', 'Cheap', 'Loud', 'Mahane-Yehuda', 'No', 'No', 'Yes'],\n",
    "#  ['High', 'Expensive', 'Loud', 'City-Center', 'Yes', 'Yes', 'Yes'],\n",
    "#  ['Low', 'Cheap', 'Quiet', 'City-Center', 'No', 'No', 'No'],\n",
    "#  ['Moderate', 'Cheap', 'Loud', 'Talpiot', 'No', 'Yes', 'No'],\n",
    "#  ['Low', 'Cheap', 'Quiet', 'Talpiot', 'Yes', 'Yes', 'No'],\n",
    "#  ['Moderate', 'Expensive', 'Quiet', 'Mahane-Yehuda', 'No', 'Yes', 'Yes'],\n",
    "#  ['High', 'Normal', 'Loud', 'Mahane-Yehuda', 'Yes', 'Yes', 'Yes'],\n",
    "#  ['Moderate', 'Normal', 'Loud', 'Ein-Karem', 'No', 'Yes', 'Yes'],\n",
    "#  ['High', 'Normal', 'Quiet', 'German-Colony', 'No', 'No', 'No'],\n",
    "#  ['High', 'Cheap', 'Loud', 'City-Center', 'No', 'Yes', 'Yes'],\n",
    "#  ['Low', 'Normal', 'Quiet', 'City-Center', 'No', 'No', 'No'],\n",
    "#  ['Low', 'Expensive', 'Loud', 'Mahane-Yehuda', 'No', 'No', 'No'],\n",
    "#  ['Moderate', 'Normal', 'Quiet', 'Talpiot', 'No', 'No', 'Yes'],\n",
    "#  ['Low', 'Normal', 'Quiet', 'City-Center', 'No', 'No', 'Yes'],\n",
    "#  ['Low', 'Cheap', 'Loud', 'Ein-Karem', 'Yes', 'Yes', 'Yes']]\n",
    "f = ['Occupied', 'Price', 'Music', 'Location', 'VIP', 'Favorite Beer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Occupied': {'2': {'Location': {'4': 'No',\n",
       "    '3': 'Yes',\n",
       "    '2': 'Yes',\n",
       "    '0': 'No'}},\n",
       "  '1': {'Location': {'3': 'Yes',\n",
       "    '0': {'VIP': {'0': 'No', '1': 'Yes'}},\n",
       "    '1': 'Yes',\n",
       "    '2': 'Yes',\n",
       "    '4': {'Price': {'0': 'No', '1': 'Yes'}}}},\n",
       "  '0': {'Location': {'1': {'Price': {'1': 'No', '0': 'Yes'}},\n",
       "    '3': {'Price': {'0': 'No',\n",
       "      '1': {'Favorite Beer': {'No': '0', 'Yes': '0'}}}},\n",
       "    '4': 'No',\n",
       "    '2': 'No'}}}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node = create_decision_tree(d, f)\n",
    "node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(node, feature_names, data):\n",
    "   # 获取当前节点判断的特征\n",
    "    key = list(node.keys())[0]\n",
    "    node = node[key]\n",
    "    idx = feature_names.index(key)\n",
    "    \n",
    "    # 根据特征进行递归\n",
    "    pred = None\n",
    "    for key in node:\n",
    "       # 找到了对应的分叉\n",
    "        if data[idx] == key:\n",
    "           # 如果再往下依然还有子树，那么则递归，否则返回结果\n",
    "            if isinstance(node[key], dict):\n",
    "                pred = classify(node[key], feature_names, data)\n",
    "            else:\n",
    "                pred = node[key]\n",
    "                \n",
    "    # 如果没有对应的分叉，则找到一个分叉返回\n",
    "    if pred is None:\n",
    "        for key in node:\n",
    "            if not isinstance(node[key], dict):\n",
    "                pred = node[key]\n",
    "                break\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1,0,1,3,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-2e23f649c916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-c22a58436d91>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(node, feature_names, data)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m        \u001b[0;31m# 找到了对应的分叉\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m            \u001b[0;31m# 如果再往下依然还有子树，那么则递归，否则返回结果\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'idx' is not defined"
     ]
    }
   ],
   "source": [
    "classify(node,f,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(node.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2': {'Location': {'4': 'No', '3': 'Yes', '2': 'Yes', '0': 'No'}},\n",
       " '1': {'Location': {'3': 'Yes',\n",
       "   '0': {'VIP': {'0': 'No', '1': 'Yes'}},\n",
       "   '1': 'Yes',\n",
       "   '2': 'Yes',\n",
       "   '4': {'Price': {'0': 'No', '1': 'Yes'}}}},\n",
       " '0': {'Location': {'1': {'Price': {'1': 'No', '0': 'Yes'}},\n",
       "   '3': {'Price': {'0': 'No',\n",
       "     '1': {'Favorite Beer': {'No': '0', 'Yes': '0'}}}},\n",
       "   '4': 'No',\n",
       "   '2': 'No'}}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'Occupied' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-aacc537cddc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: 'Occupied' is not in list"
     ]
    }
   ],
   "source": [
    "f.index(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, 3), (1, 1)])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(dataset[:][-1]).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3, 1: 1})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(dataset[:][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 1, 1, 'Yes']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Occupied', 'Price', 'Music', 'Location', 'VIP', 'Favorite Beer']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Occupied', 'Price', 'Music', 'Location', 'VIP', 'Favorite Beer']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caseNum = random.randrange(1,6)\n",
    "caseNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "listCase = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listCase[caseNum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-a7b11eef18f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "labels = Counter(dataset[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [[0, 2, 0, 0],\n",
    "       [0, 2, 1, 1],\n",
    "       [1, 0, 1, 0],\n",
    "       [1, 2, 0, 0],\n",
    "       [2, 1, 1, 1],\n",
    "       [1, 0, 0, 0],\n",
    "       [0, 1, 0, 0],\n",
    "       [2, 1, 2, 1],\n",
    "       [1, 2, 0, 0],\n",
    "       [2, 1, 2, 1],\n",
    "       [0, 1, 0, 0],\n",
    "       [1, 1, 1, 0],\n",
    "       [2, 0, 0, 0],\n",
    "       [0, 0, 2, 0],\n",
    "       [0, 1, 0, 0],\n",
    "       [0, 2, 0, 0],\n",
    "       [2, 1, 1, 1],\n",
    "       [2, 0, 1, 1],\n",
    "       [0, 1, 1, 0],\n",
    "       [0, 0, 0, 0],\n",
    "       [0, 1, 2, 1],\n",
    "       [0, 0, 0, 0],\n",
    "       [1, 0, 2, 1],\n",
    "       [1, 0, 2, 0],\n",
    "       [0, 0, 0, 0],\n",
    "       [2, 1, 0, 1],\n",
    "       [2, 0, 1, 1],\n",
    "       [2, 2, 2, 1],\n",
    "       [0, 2, 0, 0],\n",
    "       [2, 0, 2, 1],\n",
    "       [2, 0, 1, 1],\n",
    "       [0, 1, 0, 0],\n",
    "       [0, 0, 0, 0],\n",
    "       [0, 0, 0, 0],\n",
    "       [0, 0, 0, 0],\n",
    "       [1, 2, 0, 1],\n",
    "       [0, 2, 0, 0],\n",
    "       [1, 2, 0, 1],\n",
    "       [0, 0, 0, 0],\n",
    "       [1, 0, 0, 0],\n",
    "       [1, 0, 0, 0],\n",
    "       [2, 2, 0, 1],\n",
    "       [0, 2, 0, 0],\n",
    "       [1, 1, 0, 0],\n",
    "       [0, 2, 2, 1],\n",
    "       [0, 2, 0, 0],\n",
    "       [2, 0, 2, 1],\n",
    "       [1, 0, 0, 0],\n",
    "       [2, 0, 2, 1],\n",
    "       [0, 0, 1, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-11b1c5c77fb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "print(type(dataset))\n",
    "labels = Counter(dataset[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 31, 1: 19})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.array(dataset)\n",
    "print(type(dataset))\n",
    "labels = Counter(dataset[:, -1])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
